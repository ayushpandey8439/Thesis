% !TEX root = ../main.tex
%


\chapter{Introduction} \label{chap:intro}
\adjustmtc

Databases are critical components in the infrastructure of modern organizations, serving as systems for the efficient storage, management and, retrieval of vast amounts of data. As businesses and institutions increasingly pivot toward data-driven strategies, the role of databases becomes paramount, enabling organizations to leverage data for informed decision-making and operational efficiency. The importance of databases extends across various sectors, from retail and finance to healthcare and scientific research, illustrating their versatility.


Consistency in databases is crucial for ensuring the accuracy and reliability of stored data, particularly in environments with concurrent access. It guarantees that the database adheres to a defined set of rules and constraints. Without consistency, errors such as data corruption, conflicting updates, or invalid relationships between data entities can arise, undermining the system's integrity. This is vital as consistent data forms the foundation for meaningful analytics, reliable application behavior, and user trust.

In databases, managing data consistency during concurrent access is a foundational challenge. It can be specified through constraints or invariants, which are conditions on data. A database is in a consistent state when all specified invariants are satisfied. These constraints can be classified into two main types: \textbf{Physical} and \textbf{Logical}. Physical constraints typically govern structural relationships within the database. For example, \emph{if record A refers to record B, then record B must exist for the database to remain consistent}. Logical constraints, on the other hand, involve higher-level properties of the data, such as: \emph{the sum of money across all accounts in a financial system remains constant}. These constraints collectively ensure that the database behaves predictably and correctly, even under concurrent access.

The ACID (atomicity, consistency, isolation, durability) model is a set of properties that ensure validity of data. Under this model, a transaction is as a series of accesses to the database, involving reads and writes to specific data items. It is delimited by a \emph{begin} operation that marks the start of the transaction and a \emph{commit} operation that applies all the changes atomically. By grouping multiple accesses into a single unit of work, transactions provide a means to apply updates to the database as an indivisible operation. A correct transaction, when applied to a database that is initially consistent, must leave the database in a consistent state after it commits. This property ensures that the specified invariants hold true before and after every transaction.

However, this notion of correctness is primarily concerned with the final state of the database, and it does not enforce consistency during the execution of a transaction. In practice, applications that interact with a database often assume that transactions will always observe a consistent state of the database. This expectation goes beyond the pre-application and post-application consistency invariants. To meet this expectation, transactions must not only be atomic but also \textbf{isolated}. Isolation ensures that a transaction can execute as though it were the only transaction interacting with the database at that time. Without isolation, a transaction could read or write data in a temporarily inconsistent state, leading to incorrect or unpredictable outcomes. Locks are one of the mechanisms used to enforce isolation. By preventing simultaneous access to the same data by multiple transactions, locks ensure that no transaction observes intermediate, inconsistent state created by another transaction.

Modern database systems have evolved to handle increasingly complex data models, such as hierarchical structures. Hierarchical data models are widely used in domains where relationships between data elements need to be explicitly represented and managed. Examples include \textbf{File systems}, where directories and files form a hierarchy; \textbf{Organizational structures}, where departments and employees are arranged in levels; \textbf{Ontologies}, where concepts are related in a taxonomic order; \textbf{XML databases}, where data is structured in a tree-like format; and more recently, \textbf{Document stores}, where data is stored as nested objects that contain key-value pairs. These hierarchical models naturally capture relationships across different levels of abstraction, and they often involve multiple users or processes accessing the data concurrently. Typically, in these models, vertices represent data elements, while edges capture the relationships or connections between them.

In such hierarchical models, transactions access data by acquiring locks on the vertices that contain the required data. To maintain atomicity and isolation, a transaction that needs to access multiple data items may require multiple locks, often at different levels of the hierarchy. This poses challenges because the topology of the hierarchy and the access patterns of transactions are not constrained. Multi-granularity locking (MGL) is a well-established mechanism designed to address these challenges. MGL allows locks to be managed at varying levels of granularity, enabling \emph{coarse-grain} locks at higher levels of the hierarchy and \emph{fine-grain} locks at lower levels. This flexibility is critical for supporting efficient concurrency control. For example, a transaction that requires broad access to a large portion of the data can acquire a coarse-grain lock at a higher level, while another transaction that requires access to specific items can acquire fine-grain locks at lower levels. This approach minimizes contention and maximizes parallelism.

However, implementing MGL effectively in systems with hierarchical and highly interconnected data introduces unique challenges. Hierarchical data structures often have complex topologies, with relationships that span multiple levels. Efficiently managing locks in such environments requires careful consideration of both the structure of the hierarchy and the access patterns of concurrent transactions. Tailoring MGL to these scenarios is essential for achieving scalable and efficient concurrency control. By adapting MGL to hierarchical data models, it is possible to support a higher degree of parallelism while maintaining the consistency of the database. This research explores these adaptations, focusing on techniques that allow MGL to operate effectively in environments characterized by complex data relationships and diverse transaction workloads. Through these adaptations, the goal is to achieve scalable, high-performance concurrency control that ensures consistency in even the most demanding hierarchical database systems.

% In databases, managing data consistency during concurrent access is a foundational challenge. 
% Consistency can be specified in the form of constraints or invariants. When all specified invariants are satisfied, a database is considered consistent. 
% Database constraints can be \textbf{physical}, e.g. \emph{If record A refers to record B, then record B must exist}, or \textbf{logical}, e.g. \emph{The sum of money in all accounts must be constant}.


% A transaction is a series of accesses (reads and writes) to data. It is delimited by a \emph{begin} and a \emph{commit}. Together, they group accesses into a single unit of work which is applied atomically.  
% A correct transaction, when applied to a consistent database, should produce a consistent database.

% However, this notion of correctness does not enforce interim database consistency during a transaction's execution. An application that accesses a database assumes that transactions always \emph{observe} a consistent state.  The pre-application and post-application consistency invariant is not strong enough to guarantee this. Alongside atomicity, a transaction must also remain \textbf{isolated} i.e., it should be able to access the database as if it were the only transaction running. 
% Locks provide a way to implement isolation and prevent a transaction from observing temporarily inconsistent data produced by other concurrent transactions. 



% Modern databases have evolved to incorporate complex data models like hierarchies. These data models are common in domains such as file systems, organizational structures, ontologies, and XML databases. They naturally capture relationships across different levels of abstraction, where data elements can be accessed concurrently by multiple users or processes. Typically, in such models, data is contained in vertices and relationships are represented by edges.

% Evidently, in these models, transactions access data by acquiring locks on the vertices that contain said data. In order to access multiple data items atomically and in isolation, a thread may need to acquire multiple locks. 
% Since the topology of a hierarchy and the access pattern is unconstrained, these locks may exist at different levels of the hierarchy.  
% \emph{Multi-granularity locking} (MGL) provides a mechanism to manage locks at varying levels, allowing coarse-grain locks at higher levels of a hierarchy and fine-grain locks at lower levels. This flexibility supports efficient concurrency control by enabling transactions to lock large portions of data when broad access is required or smaller segments for more specific access. 
% However, implementing MGL effectively in systems with complex, interconnected data introduces unique challenges. 

% MGL needs to be tailored to hierarchical data to achieve scalable, efficient concurrency control that ensures data consistency. 
% This research explores adaptations of MGL to support a greater degree of parallelism while maintaining consistency in environments characterized by complex topologies. 

% In database systems, maintaining data consistency and integrity during concurrent access is a foundational challenge. As systems grow in scale and complexity, managing data concurrency effectively becomes critical, especially in scenarios where multiple transactions access shared data simultaneously. Locking mechanisms provide a structured approach to concurrency control, with multi-granularity locking (MGL) being a particularly valuable technique. MGL has been widely studied in traditional database settings, especially for table spaces organized in tree-structured data, where it efficiently manages hierarchical access patterns.

% However, as data models evolve to incorporate intricate hierarchies and highly connected structures like graphs and networks, traditional approaches to MGL require adaptation. Hierarchical data models are common in domains such as file systems, organizational structures, ontologies, and XML databases. These models naturally capture relationships across different levels of abstraction, where data elements can be accessed concurrently by multiple users or processes. Such concurrent access raises the possibility of conflicts and inconsistencies, particularly when different parts of the hierarchy or network are accessed simultaneously.

% To address these issues, MGL provides a mechanism to manage locks at varying levels of granularity, allowing coarse-grained locks at higher levels of the hierarchy and fine-grained locks at lower levels. This flexibility supports efficient concurrency control by enabling transactions to lock large portions of data when broad access is required or smaller segments for more specific operations. However, implementing MGL effectively in systems with complex hierarchies and interconnected data structures introduces unique challenges. Balancing performance with fairness becomes crucial, as the system’s performance depends on minimizing lock contention and avoiding deadlocks, while ensuring that locks at different levels can coexist without causing unnecessary blocks or resource wastage.

% In summary, as data structures grow more intricate, a deeper understanding of multi-granularity locking tailored to hierarchical and graph-based data is essential for achieving scalable, efficient concurrency control. This research aims to address these complexities, exploring adaptations of MGL that can support parallelism and data integrity in environments characterized by complex, multi-level connections.


% \section{Background and Motivation}
% Overview of concurrency control and the importance of locking in database systems. Challenges associated with multi-granularity locking. Introduction to CALock and its significance.

% \section{Research Objectives}
% Define the main goals of the research. Specific objectives related to CALock and optimal locking grain.

\section{Problem Statement}

While multi-granularity locking (MGL) is widely applied in simple hierarchical data models, adapting it to handle complex, irregular, and deeply nested hierarchies remains a significant challenge. In its traditional form, MGL is well-suited to environments where the hierarchy has predictable and straightforward structures. However, as hierarchies grow larger and more intricate, scalability becomes a pressing issue. This is particularly true in scenarios where the size and depth of the hierarchy expand significantly, or where the relationships between elements deviate from strict hierarchical patterns, approaching those of graph-like data models. These complexities introduce obstacles that make straightforward adaptations of traditional MGL frameworks insufficient.

One of the core challenges lies in the efficient determination of a \textbf{lockable unit} within these intricate structures. A lockable unit represents a portion of the hierarchy on which a transaction can safely operate in isolation, without causing conflicts with other concurrent transactions. In hierarchies with simple topologies, like trees, this is often a straightforward task because the structure itself guides the placement of locks. However, in hierarchies characterized by significant depth and irregularity, identifying appropriate lockable units becomes increasingly difficult. This process must account for the complexity of the hierarchy’s topology, which is dynamic and evolves as transactions update data. As a result, determining lockable units in such scenarios can become computationally intensive, requiring careful consideration of the hierarchy’s structure to maintain efficiency.

Once locks are established, managing and resolving conflicts between them poses another substantial challenge. In simple hierarchical data models, conflicts are often limited to well-defined scenarios, such as two transactions attempting to access the same vertex or its immediate descendants. However, in more complex hierarchies, transactions may interact with multiple levels of the hierarchy simultaneously, creating more intricate conflict scenarios. The irregularity and depth of the structure further complicate the process of conflict detection and resolution, as transactions may inadvertently interact with distant or seemingly unrelated parts of the hierarchy. This increases the complexity of ensuring that transactions proceed without violating the isolation property of concurrency control.

% These challenges are compounded in distributed environments, where additional factors such as network latency and partitioning further hinder the efficient operation of locking mechanisms. Distributed systems introduce delays in communication between nodes, making it difficult to coordinate lock placement and ensure consistency. Frequent partitioning or intermittent connectivity can exacerbate these issues, potentially leading to scenarios where locks are lost, inconsistent, or delayed in propagation. These conditions introduce significant synchronization challenges that must be addressed to maintain system performance and ensure that locks remain effective at preserving consistency.

To address these issues, it is necessary to extend existing MGL frameworks to better accommodate complex dynamic hierarchical data. Such extensions must focus on two critical aspects: \textbf{efficient lock placement} and \textbf{conflict management}. Lock placement must be tailored to the unique characteristics of intricate hierarchies, ensuring that lockable units are defined in a way that balances the need for fine-grained control with the need to minimize overhead. Conflict management must scale effectively with the complexity of the hierarchy and the level of parallelism, providing mechanisms to detect and resolve conflicts in a timely and efficient manner. These enhancements must be designed to ensure that the fundamental goals of MGL—scalability, high performance, and data consistency—are upheld, even in environments with irregular and deeply nested structures.

By extending MGL to meet these requirements, it becomes possible to support concurrency control in even the most challenging hierarchical models. These adaptations aim to preserve the key benefits of MGL while addressing the unique demands posed by environments characterized by structural irregularity, increased depth, and distributed operation.




% While multi-granularity locking (MGL) is widely applied in simple hierarchical data models, adapting it to handle complex, irregular, and deeply nested hierarchies remains challenging. Traditional MGL approaches often face scalability issues in environments where hierarchies expand significantly in size and depth, or where relationships become less rigid, as in graph-like data models. One core challenge lies in efficiently determining a \emph{lockable unit} in these intricate structures. 
% This must consider both the structural depth and irregularity of the hierarchy, which can make lock placement a computationally intensive task.

% Furthermore, once locks are set, identifying and managing conflicts between them becomes increasingly complex, especially as parallel transactions interact at multiple levels of the hierarchy. These interactions can introduce significant synchronization challenges, particularly in distributed environments with high latency or frequent partitioning. Addressing these issues requires an extension of existing MGL frameworks that supports not only efficient lock placement and conflict detection but also maintains high performance and data consistency across complex hierarchical structures.


\section{Contributions}

In this work, we present CALock, a novel MGL protocol specifically designed to address the challenges of concurrency control in complex dynamic hierarchical data models. CALock extends the traditional MGL framework to support hierarchies with arbitrary depth, structural complexity and dynamic topology, enabling efficient and scalable concurrency management across diverse application domains. By adapting MGL principles to account for the intricacies of highly interconnected, dynamic hierarchical data, CALock ensures both high performance and data consistency, even under challenging workloads.

MGL techniques establish a granularity at which a transaction acquires a lock, optimizing access based on the specific needs of the transaction. CALock innovates in this area by employing a partial ordering of the vertices in the hierarchy to determine lock granularity dynamically. This ordering is defined through a vertex labeling scheme, where each vertex is assigned a label that represents a set of its common ancestors. These labels are computed recursively using a breadth-first traversal of the hierarchy, capturing the hierarchical relationships efficiently. At runtime, these vertex labels provide a means to identify the most appropriate lock granularity for any given lock request, tailoring the locking strategy to the transaction’s specific access pattern. As a hierarchy evolves, CALock adapts the lock granularity by efficiently updating vertex labels, ensuring that locks remain effective and efficient even as the structure of the hierarchy changes.

One of the core principles of CALock is to minimize the granularity of locks wherever possible. By doing so, CALock ensures that each lock covers only the smallest necessary portion of the hierarchy, thereby improving the level of parallelism available to concurrent transactions. An additional benefit of CALock is its ability to eliminate the need for a fixed vertex ordering, which is a common requirement in many other MGL techniques. This design choice avoids the overhead associated with frequent relabeling of vertices as the hierarchy evolves, reducing computational costs while still maintaining the same level of correctness and isolation guarantees as other MGL protocols.

Through its novel approach to lock granularity and its adaptive labeling mechanism, CALock offers a robust solution for concurrency control in complex, irregular and hierarchies. These features make it particularly well-suited for environments requiring high scalability and dynamic adaptability.

% In this work, we present CALock, a novel MGL protocol designed to address the challenges of concurrency control in complex hierarchical data models. CALock extends the traditional MGL framework to support hierarchies with arbitrary depth and complexity, enabling efficient and scalable concurrency management.

% MGL techniques establish a granularity at which a transaction acquires a lock, to optimize access based on the transaction's needs. In CALock, we use a partial ordering of the vertices in the hierarchy to establish this granularity. This ordering is defined through a vertex labelling scheme.  Each vertex label is a set of common ancestors of the vertex, computed recursively through breadth-first traversal.
% At runtime, these labels help determine the most suitable lock granularity for a given lock request based on the transaction’s access pattern.

% CALock attempts to minimize the granularity of a lock, ensuring that each lock covers the smallest necessary portion of a hierarchy. 
% An added benefit of CALock is that it avoids the need for fixed vertex ordering, which is common in other MGL techniques. This eliminates the overhead of frequent relabelling, while still providing the same guarantees as other MGL protocols.


% Existing MGL techniques like intention locks \cite{gray1975granularity} use the topology of the hierarchy to detect lock conflicts but require multiple traversals from the root of the graph to the vertices being locked. 
% This makes them expensive for non-tree-like hierarchies like DAGs. Label based techniques \cite{kalikar2016domlock,anjuMID,kalikar_toggle_2019,FlexiGran2024} use an ordering of vertices to assign labels that eliminate the need for traversals. However these have poor performance over dynamic graphs due to the overhead of relabelling. 


% In this work, we present CALock, a novel multi-granularity locking protocol designed to address the challenges of managing concurrency in complex hierarchical data models.
% CALock extends the traditional multi-granularity locking framework to support hierarchies with arbitrary levels of depth and complexity, enabling efficient and scalable concurrency control.
% We use a topological partial ordering of the vertices of a hierarchy to define the lock levels and grains, allowing transactions to acquire locks at different levels of granularity based on their access patterns. 
% This topological ordering is determined via a labelling scheme that assigns unique labels to each vertex in the hierarchy which are used at runtime to determine the appropriate lock grain for a lock request. 



% CALock's labelling efficiently computes the closest common ancestor of a set of vertices in a rooted directed graph. 
% By choosing the closest common ancestor of a set of lock targets as their guard, CALock minimizes grain size. 
% In using paths, by avoiding a fixed ordering of vertices, CALock circumvents expensive relabelling while providing the same locking guarantees as other MGL techniques. 
% The label of a vertex in the graph is a set of its common ancestors, computed recursively via breadth-first traversal.



\section{Thesis Structure}
The remainder of this thesis is organized as follows:

 Chapter \ref{chap:background} presents an overview of concurrency control, multi-granularity locking and the challenges associated with complex hierarchical data models. 

 Chapter \ref{chap:relatedwork} reviews existing research in the field of multi-granularity locking, highlighting the limitations of current techniques. 

 Chapter \ref{chap:theory} provides a theoretical framework for CALock which includes the concept of lowest common ancestors in graphs, and the problem formulation for optimal locking grain selection and the proof of optimality of CALock labelling.

 Chapter \ref{chap:calock} introduces CALock, our novel multi-granularity locking protocol, and describes its design and implementation. We also discuss the properties of CALock like safety, liveness and fairness.

Chapter \ref{chap:formalProperties} discusses the formal properties of CALock, including safety, liveness, and fairness. We also present the complexity analysis of CALock and compare it against state-of-the-art techniques.

 Chapter \ref{chap:implementation} describes the implementation of CALock, including the design choices and optimizations made to improve performance.
 
 Chapter \ref{chap:evaluation} presents an experimental evaluation of CALock, comparing its performance against state-of-the-art techniques in a variety of scenarios using both, micro-benchmarks and macro-benchmarks.
 
 Finally, Chapter \ref{chap:conclusion} concludes the thesis, summarizing our contributions and outlining future research directions in the field of multi-granularity locking for complex hierarchical data models.

% \begin{itemize}
%     \item Chapter 2 provides an overview of the background and motivation for this work, including a discussion of the challenges associated with multi-granularity locking in complex hierarchical data models.
%     \item Chapter 3 presents a detailed review of related work in the field of multi-granularity locking, focusing on existing techniques and their limitations in managing concurrency in hierarchical data models.
%     \item Chapter 4 introduces CALock, our novel multi-granularity locking protocol designed to address the challenges of concurrency control in complex hierarchical data models. We describe the design and implementation of CALock, and evaluate its performance in comparison to existing techniques.
%     \item Chapter 5 presents an experimental evaluation of CALock, comparing its performance against state-of-the-art multi-granularity locking techniques in a variety of scenarios. We analyze the results and discuss the implications of our findings.
%     \item Chapter 6 concludes the thesis, summarizing our contributions and outlining future research directions in the field of multi-granularity locking for complex hierarchical data models.

% \chapter{Applications and Case Studies}
% \section{Application Scenarios}
% Potential real-world applications of CALock in database systems.

% \section{Case Studies}
% Detailed analysis of specific case studies where CALock was applied.

% \section{Lessons Learned}
% Insights gained from practical applications.





% \chapter{Introduction}
% \label{sec:intro}

% main intro part, in general it should contain at least 4 paragraphs each answers one of the following questions.

% \emph{P1: What's the thesis main problem?}

% \emph{P2: Why the problem is a problem?}

% \emph{P3: what's the solution?}

% \emph{P4: Why the solution is better than the state of the art?}

% \section{Overview}
% \label{sec:intro:overview}

% In the first part of this thesis,
% we explore ...

% In the second part of the thesis,
% we present \system{},
% a ...
% To answer this challenge, \system{} takes a hybrid approach, and
% ...

% To address the requirements of ..., \system{}
% enables ...

% Finally, this thesis addresses a number of design and implementation
% challenges, including ...

% \section{Contributions}
% \label{sec:intro:contributions}

% The main results of this dissertation are as follows:
% \begin{itemize}[leftmargin=*]
% \item
%   R1
% \item
%   R2
% \item
%   R3
% \item
%   R4
% \item
%   R5
% \end{itemize}

% Our experimental evaluation shows that:...

% \section{Publications}
% \label{sec:intro:publications}

% Some of the results presented in this thesis have been published as follows:

% \begin{itemize}
%   \item myFirstPublication %\cite{toumlilt:hal-03353663}
%   \item mySecondPublication %\cite{toumlilt:hal-01860334}
% \end{itemize}

% During my thesis, I explored other directions and collaborated in several projects that have helped me to get insights on the challenges of ... These efforts have led me to contribute to the following publications and deliverables:

% \begin{itemize}
%   \item TechReport %\cite{LiRAv09p46:online}
%   \item ANRProjectDelivrable %\cite{D61Newco32:online}
%   \item EUProjectDelivrable %\cite{D62Newco60:online}
% \end{itemize}

% \section{Organization}
% \label{sec:intro:organisation}

% This thesis is divided into three parts. 
% The rest of this document is organized as follows:
% \begin{itemize}
%   \item Part~\ref{part:background} introduces the common background of our work,
%   formulate the problem, presents the existing solutions and discusses the use-case
%   requirements, this part is divided into three chapters:
%   \begin{itemize}
%     \item Chapter~\ref{ch:my-domain} provides a complete and up-to-date 
%     review of the MyDomain.
%     \item Chapter~\ref{ch:requirements} presents a use-case point of view of the
%     ...
%     \item Chapter~\ref{ch:related-work} studies and compares the solutions that have
%     been designed in the state of the art of ...
%   \end{itemize}
%   \item Part~\ref{part:contributions}, in light of what we saw in the existing work, 
%   we will here justify some protocol choices used in our approach...
%   \item Part~\ref{part:evaluation} provides an experimental evaluation 
%   demonstrating the benefits of our approach, compared to other solutions 
%   from the state of the art.
%   \item the last part~\ref{part:conclusion} we summarize our contribution, and 
%   present our vision for the future requirements towards more ...
% \end{itemize}
